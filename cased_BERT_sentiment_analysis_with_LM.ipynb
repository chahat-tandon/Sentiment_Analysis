{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cased BERT sentiment-analysis-with-LM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f8b1fe08222424aa5a19fd0f207ceb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_755e4596fdb14f0c84cbed89f9f4f122",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff1f4ccff3b54ec6aaea9be98a348c53",
              "IPY_MODEL_8a8e0bb24a6a4a569d2eddc8de05bf90"
            ]
          }
        },
        "755e4596fdb14f0c84cbed89f9f4f122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff1f4ccff3b54ec6aaea9be98a348c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6c35bb360f547ca8ce807b1a5a5d790",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a775c642f3d417ca941a0971fc74908"
          }
        },
        "8a8e0bb24a6a4a569d2eddc8de05bf90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4358c5e6f1854d51b7e9a976c9908866",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 282kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd7bda0105884c07a5a9c2b0ebcb6845"
          }
        },
        "c6c35bb360f547ca8ce807b1a5a5d790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a775c642f3d417ca941a0971fc74908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4358c5e6f1854d51b7e9a976c9908866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd7bda0105884c07a5a9c2b0ebcb6845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75196b79ff4640b39f02f4ee74dc49f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_10a168364c6b47088b27841c63ff63e7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a07f30d670544dfb5c0e0d000d41f92",
              "IPY_MODEL_4c00e7891513490dac8b69d08b8358e5"
            ]
          }
        },
        "10a168364c6b47088b27841c63ff63e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a07f30d670544dfb5c0e0d000d41f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_310babb841f34b5c842a6abd15bfb5bc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53f42edc57964019a24d81e782d94528"
          }
        },
        "4c00e7891513490dac8b69d08b8358e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1beeca0e3284185848048965ed31da5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.01kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cd3680ac66c4ef584c2d343ad2a76d6"
          }
        },
        "310babb841f34b5c842a6abd15bfb5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53f42edc57964019a24d81e782d94528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1beeca0e3284185848048965ed31da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cd3680ac66c4ef584c2d343ad2a76d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eed7481eeb5c48268f5447a594c081ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_300acc7f841b4ab1a39d1b6d7d37dce4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f30a5a842d649a6947e6e87dc3b944f",
              "IPY_MODEL_15f2d5d6c7364ddb811c6f1a7387cebc"
            ]
          }
        },
        "300acc7f841b4ab1a39d1b6d7d37dce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f30a5a842d649a6947e6e87dc3b944f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_104239cc072f49f999b5c2dfedca6958",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c035c76981b4ac19db24d5e1c01c66b"
          }
        },
        "15f2d5d6c7364ddb811c6f1a7387cebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_357bcf0ef4c2457ca16fc36876112cc9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [01:33&lt;00:00, 4.66MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b78f0212b5046d68c87fb284ff76e44"
          }
        },
        "104239cc072f49f999b5c2dfedca6958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c035c76981b4ac19db24d5e1c01c66b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "357bcf0ef4c2457ca16fc36876112cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b78f0212b5046d68c87fb284ff76e44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGnlRWvkY-2c"
      },
      "source": [
        "# Sentiment Analysis with BERT\n",
        "\n",
        "> TL;DR In this tutorial, you'll learn how to fine-tune BERT for sentiment analysis. You'll do the required text preprocessing (special tokens, padding, and attention masks) and build a Sentiment Classifier using the amazing Transformers library by Hugging Face!\n",
        "\n",
        "- [Read the tutorial](https://www.curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/)\n",
        "- [Run the notebook in your browser (Google Colab)](https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S)\n",
        "- [Read the `Getting Things Done with Pytorch` book](https://github.com/curiousily/Getting-Things-Done-with-Pytorch)\n",
        "\n",
        "You'll learn how to:\n",
        "\n",
        "- Intuitively understand what BERT is\n",
        "- Preprocess text data for BERT and build PyTorch Dataset (tokenization, attention masks, and padding)\n",
        "- Use Transfer Learning to build Sentiment Classifier using the Transformers library by Hugging Face\n",
        "- Evaluate the model on test data\n",
        "- Predict sentiment on raw text\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH8xHMfdX974",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "016f6357-f5f0-493b-b473-e1a0be06e1bf"
      },
      "source": [
        "#@title Watch the video tutorial\n",
        "\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('8N-nM3QW7O0', width=720, height=420)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"720\"\n",
              "            height=\"420\"\n",
              "            src=\"https://www.youtube.com/embed/8N-nM3QW7O0\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f11e088d390>"
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ6MhJYYBCwu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "28bc0db9-5720-43b8-e7ec-d2483c6ad1f6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep 22 08:45:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbodro8Fpmwr"
      },
      "source": [
        "## What is BERT?\n",
        "\n",
        "BERT (introduced in [this paper](https://arxiv.org/abs/1810.04805)) stands for Bidirectional Encoder Representations from Transformers. If you don't know what most of that means - you've come to the right place! Let's unpack the main ideas:\n",
        "\n",
        "- Bidirectional - to understand the text  you're looking you'll have to look back (at the previous words) and forward (at the next words)\n",
        "- Transformers - The [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper presented the Transformer model. The Transformer reads entire sequences of tokens at once. In a sense, the model is non-directional, while LSTMs read sequentially (left-to-right or right-to-left). The attention mechanism allows for learning contextual relations between words (e.g. `his` in a sentence refers to Jim).\n",
        "- (Pre-trained) contextualized word embeddings - [The ELMO paper](https://arxiv.org/abs/1802.05365v2) introduced a way to encode words based on their meaning/context. Nails has multiple meanings - fingernails and metal nails.\n",
        "\n",
        "BERT was trained by masking 15% of the tokens with the goal to guess them. An additional objective was to predict the next sentence. Let's look at examples of these tasks:\n",
        "\n",
        "### Masked Language Modeling (Masked LM)\n",
        "\n",
        "The objective of this task is to guess the masked tokens. Let's look at an example, and try to not make it harder than it has to be:\n",
        "\n",
        "That's `[mask]` she `[mask]` -> That's what she said\n",
        "\n",
        "### Next Sentence Prediction (NSP)\n",
        "\n",
        "Given a pair of two sentences, the task is to say whether or not the second follows the first (binary classification). Let's continue with the example:\n",
        "\n",
        "*Input* = `[CLS]` That's `[mask]` she `[mask]`. [SEP] Hahaha, nice! [SEP]\n",
        "\n",
        "*Label* = *IsNext*\n",
        "\n",
        "*Input* = `[CLS]` That's `[mask]` she `[mask]`. [SEP] Dwight, you ignorant `[mask]`! [SEP]\n",
        "\n",
        "*Label* = *NotNext*\n",
        "\n",
        "The training corpus was comprised of two entries: [Toronto Book Corpus](https://arxiv.org/abs/1506.06724) (800M words) and English Wikipedia (2,500M words). While the original Transformer has an encoder (for reading the input) and a decoder (that makes the prediction), BERT uses only the decoder.\n",
        "\n",
        "BERT is simply a pre-trained stack of Transformer Encoders. How many Encoders? We have two versions - with 12 (BERT base) and 24 (BERT Large).\n",
        "\n",
        "### Is This Thing Useful in Practice?\n",
        "\n",
        "The BERT paper was released along with [the source code](https://github.com/google-research/bert) and pre-trained models.\n",
        "\n",
        "The best part is that you can do Transfer Learning (thanks to the ideas from OpenAI Transformer) with BERT for many NLP tasks - Classification, Question Answering, Entity Recognition, etc. You can train with small amounts of data and achieve great performance!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmj22-TcZMef"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We'll need [the Transformers library](https://huggingface.co/transformers/) by Hugging Face:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_7Tz0-pK69"
      },
      "source": [
        "!pip install -q -U watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjsbi1u3QFEM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "aa0ebaaa-0528-4cb2-aba3-4942777be383"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 890kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 44.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 38.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 41.5MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJqoaFpVpoM8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d0c45006-09e8-4639-dc06-431ef1541eca"
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p numpy,pandas,torch,transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPython 3.6.9\n",
            "IPython 5.5.0\n",
            "\n",
            "numpy 1.18.5\n",
            "pandas 1.0.5\n",
            "torch 1.6.0+cu101\n",
            "transformers 3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzHYY2lDnyuj"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w68CZpOwFoly",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "474343ff-f3c8-4d80-80a4-9111a0f82e27"
      },
      "source": [
        "#@title Setup & Config\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
        "\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "\n",
        "rcParams['figure.figsize'] = 12, 8\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufzPdoTtNikq"
      },
      "source": [
        "## Data Exploration\n",
        "\n",
        "We'll load the Google Play app reviews dataset, that we've put together in the previous part:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgPRhuMzi9ot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "534b7015-a63e-4b06-b7ed-75956f8e6a58"
      },
      "source": [
        "!gdown --id 1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
        "!gdown --id 1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1S6qMioqPJjyBLpLVz4gmRTnJHnjitnuV\n",
            "To: /content/apps.csv\n",
            "100% 134k/134k [00:00<00:00, 50.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zdmewp7ayS4js4VtrJEHzAheSW-5NBZv\n",
            "To: /content/reviews.csv\n",
            "7.17MB [00:00, 112MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKLyKc7I6Qp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "2ca35393-23f0-4b87-e132-3f703b5b425e"
      },
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>Update: After getting a response from the deve...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>Used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>Your app sucks now!!!!! Used to be good but no...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>It seems OK, but very basic. Recurring tasks n...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>Absolutely worthless. This app runs a prohibit...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           userName  ...      appId\n",
              "0     Andrew Thomas  ...  com.anydo\n",
              "1      Craig Haines  ...  com.anydo\n",
              "2     steven adkins  ...  com.anydo\n",
              "3  Lars Panzerbjørn  ...  com.anydo\n",
              "4     Scott Prewitt  ...  com.anydo\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l170zlPzFoc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "0aaa6389-103a-4f45-b3c5-43a1e1a427ce"
      },
      "source": [
        "df['content']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Update: After getting a response from the deve...\n",
              "1        Used it for a fair amount of time without any ...\n",
              "2        Your app sucks now!!!!! Used to be good but no...\n",
              "3        It seems OK, but very basic. Recurring tasks n...\n",
              "4        Absolutely worthless. This app runs a prohibit...\n",
              "                               ...                        \n",
              "15741    I believe that this is by far the best app wit...\n",
              "15742                         It sometimes crashes a lot!!\n",
              "15743                           Works well for what I need\n",
              "15744                                             Love it.\n",
              "15745    Really amazing and helped me sooo much just i ...\n",
              "Name: content, Length: 15746, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB2jE6am7Dpo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac3cdaca-b3c8-4415-ad25-62740e722396"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15746, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWqVNHJbn10l"
      },
      "source": [
        "We have about 16k examples. Let's check for missing values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA_wGSLQLKCh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "10a089a3-a4a6-4b9c-be07-fae8d35a8582"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15746 entries, 0 to 15745\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   userName              15746 non-null  object\n",
            " 1   userImage             15746 non-null  object\n",
            " 2   content               15746 non-null  object\n",
            " 3   score                 15746 non-null  int64 \n",
            " 4   thumbsUpCount         15746 non-null  int64 \n",
            " 5   reviewCreatedVersion  13533 non-null  object\n",
            " 6   at                    15746 non-null  object\n",
            " 7   replyContent          7367 non-null   object\n",
            " 8   repliedAt             7367 non-null   object\n",
            " 9   sortOrder             15746 non-null  object\n",
            " 10  appId                 15746 non-null  object\n",
            "dtypes: int64(2), object(9)\n",
            "memory usage: 1.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3cL_1qVn_6h"
      },
      "source": [
        "Great, no missing values in the score and review texts! Do we have class imbalance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwh_rW4Efhs3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "2366cc51-03f8-4e09-c5d1-8e3ac39e9df4"
      },
      "source": [
        "sns.countplot(df.score)\n",
        "plt.xlabel('review score');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 745,
              "height": 489
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZM0GKviobjM"
      },
      "source": [
        "That's hugely imbalanced, but it's okay. We're going to convert the dataset into negative, neutral and positive sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5mjZ-8JYNaL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "74b8133e-7062-4f0a-8266-acd929cdcde6"
      },
      "source": [
        "import re \n",
        "import string   \n",
        "for i,j in df.iterrows(): \n",
        "  df['content'][i] = str(' '.join(re.sub('['+string.punctuation+']', '', df['content'][i]).split()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XlUS7gbdNvB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "outputId": "d83ad597-f8ad-48be-b191-292307bfaf4a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>sortOrder</th>\n",
              "      <th>appId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Andrew Thomas</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiHd...</td>\n",
              "      <td>update after getting a response from the devel...</td>\n",
              "      <td>1</td>\n",
              "      <td>21</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-05 22:25:57</td>\n",
              "      <td>According to our TOS, and the term you have ag...</td>\n",
              "      <td>2020-04-05 15:10:24</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Craig Haines</td>\n",
              "      <td>https://lh3.googleusercontent.com/-hoe0kwSJgPQ...</td>\n",
              "      <td>used it for a fair amount of time without any ...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-04 13:40:01</td>\n",
              "      <td>It sounds like you logged in with a different ...</td>\n",
              "      <td>2020-04-05 15:11:35</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>steven adkins</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiXw...</td>\n",
              "      <td>your app sucks now used to be good but now doe...</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>4.17.0.3</td>\n",
              "      <td>2020-04-01 16:18:13</td>\n",
              "      <td>This sounds odd! We are not aware of any issue...</td>\n",
              "      <td>2020-04-02 16:05:56</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lars Panzerbjørn</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg-h...</td>\n",
              "      <td>it seems ok but very basic recurring tasks nee...</td>\n",
              "      <td>1</td>\n",
              "      <td>192</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-12 08:17:34</td>\n",
              "      <td>We do offer this option as part of the Advance...</td>\n",
              "      <td>2020-03-15 06:20:13</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scott Prewitt</td>\n",
              "      <td>https://lh3.googleusercontent.com/-K-X1-YsVd6U...</td>\n",
              "      <td>absolutely worthless this app runs a prohibiti...</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>4.17.0.2</td>\n",
              "      <td>2020-03-14 17:41:01</td>\n",
              "      <td>We're sorry you feel this way! 90% of the app ...</td>\n",
              "      <td>2020-03-15 23:45:51</td>\n",
              "      <td>most_relevant</td>\n",
              "      <td>com.anydo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15741</th>\n",
              "      <td>Tammy Kay</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GhYP...</td>\n",
              "      <td>i believe that this is by far the best app wit...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-02-17 06:09:03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15742</th>\n",
              "      <td>Ysm Johan</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Ggmd...</td>\n",
              "      <td>it sometimes crashes a lot</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.3.7</td>\n",
              "      <td>2018-02-15 10:45:22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15743</th>\n",
              "      <td>casey dearden</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14Gg2U...</td>\n",
              "      <td>works well for what i need</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.3.7</td>\n",
              "      <td>2018-02-09 18:40:37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15744</th>\n",
              "      <td>Jerry G Tamate</td>\n",
              "      <td>https://lh3.googleusercontent.com/a-/AOh14GiTP...</td>\n",
              "      <td>love it</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-02-06 12:36:17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15745</th>\n",
              "      <td>Ahmed elsalamouni</td>\n",
              "      <td>https://lh3.googleusercontent.com/-9QSxVUhCoDI...</td>\n",
              "      <td>really amazing and helped me sooo much just i ...</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>4.3.7</td>\n",
              "      <td>2018-02-04 22:57:09</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>newest</td>\n",
              "      <td>com.appxy.planner</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15746 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                userName  ...              appId\n",
              "0          Andrew Thomas  ...          com.anydo\n",
              "1           Craig Haines  ...          com.anydo\n",
              "2          steven adkins  ...          com.anydo\n",
              "3       Lars Panzerbjørn  ...          com.anydo\n",
              "4          Scott Prewitt  ...          com.anydo\n",
              "...                  ...  ...                ...\n",
              "15741          Tammy Kay  ...  com.appxy.planner\n",
              "15742          Ysm Johan  ...  com.appxy.planner\n",
              "15743      casey dearden  ...  com.appxy.planner\n",
              "15744     Jerry G Tamate  ...  com.appxy.planner\n",
              "15745  Ahmed elsalamouni  ...  com.appxy.planner\n",
              "\n",
              "[15746 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei0xmdi1Chp0"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  rating = int(rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else: \n",
        "    return 2\n",
        "\n",
        "df['sentiment'] = df.score.apply(to_sentiment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-155O-SFSqE"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3tY3ECJDPaz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "1f0ee842-7ee9-4752-a856-8c960df58a08"
      },
      "source": [
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 745,
              "height": 489
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOssB4CKnAX2"
      },
      "source": [
        "The balance was (mostly) restored."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aHyGuTFgyPO"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "You might already know that Machine Learning models don't work with raw text. You need to convert text to numbers (of some sort). BERT requires even more attention (good one, right?). Here are the requirements: \n",
        "\n",
        "- Add special tokens to separate sentences and do classification\n",
        "- Pass sequences of constant length (introduce padding)\n",
        "- Create array of 0s (pad token) and 1s (real token) called *attention mask*\n",
        "\n",
        "The Transformers library provides (you've guessed it) a wide variety of Transformer models (including BERT). It works with TensorFlow and PyTorch! It also includes prebuild tokenizers that do the heavy lifting for us!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7Mj-0ne--5t"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMSr7C-F_sey"
      },
      "source": [
        "> You can use a cased and uncased version of BERT and tokenizer. I've experimented with both. The cased version works better. Intuitively, that makes sense, since \"BAD\" might convey more sentiment than \"bad\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiLb-ltM-ZRz"
      },
      "source": [
        "Let's load a pre-trained [BertTokenizer](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3AfJSZ8NNLF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "9f8b1fe08222424aa5a19fd0f207ceb3",
            "755e4596fdb14f0c84cbed89f9f4f122",
            "ff1f4ccff3b54ec6aaea9be98a348c53",
            "8a8e0bb24a6a4a569d2eddc8de05bf90",
            "c6c35bb360f547ca8ce807b1a5a5d790",
            "7a775c642f3d417ca941a0971fc74908",
            "4358c5e6f1854d51b7e9a976c9908866",
            "cd7bda0105884c07a5a9c2b0ebcb6845"
          ]
        },
        "outputId": "ee0af3c5-6266-478b-83d8-59ff996193c8"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f8b1fe08222424aa5a19fd0f207ceb3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfrSbwTQ-wi_"
      },
      "source": [
        "We'll use this text to understand the tokenization process:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZMitwrqm2eb"
      },
      "source": [
        "sample_txt = 'When was I last outside? I am stuck at home for 2 weeks!!'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkeHCV0VkTi-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "7dd3ca01-5eed-41bb-dadb-1ecead45f258"
      },
      "source": [
        "!pip install clean-text[gpl]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: clean-text[gpl] in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: ftfy<6.0,>=5.8 in /usr/local/lib/python3.6/dist-packages (from clean-text[gpl]) (5.8)\n",
            "Requirement already satisfied: unidecode<2.0.0,>=1.1.1; extra == \"gpl\" in /usr/local/lib/python3.6/dist-packages (from clean-text[gpl]) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy<6.0,>=5.8->clean-text[gpl]) (0.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWfUr5YsT2fo"
      },
      "source": [
        "from cleantext import clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKLLxAnUi-OL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "b81f15e2-7db2-4b8e-9d84-0f345bd03507"
      },
      "source": [
        "'''\n",
        "clean(sample_txt,\n",
        "    fix_unicode=True,               # fix various unicode errors\n",
        "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
        "    lower=True,                     # lowercase text\n",
        "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
        "    no_urls=False,                  # replace all URLs with a special token\n",
        "    no_emails=False,                # replace all email addresses with a special token\n",
        "    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
        "    no_numbers=False,               # replace all numbers with a special token\n",
        "    no_digits=False,                # replace all digits with a special token\n",
        "    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
        "    no_punct = True,                 # fully remove punctuation\n",
        "    replace_with_url=\"<URL>\",\n",
        "    replace_with_email=\"<EMAIL>\",\n",
        "    replace_with_phone_number=\"<PHONE>\",\n",
        "    replace_with_number=\"<NUMBER>\",\n",
        "    replace_with_digit=\"0\",\n",
        "    replace_with_currency_symbol=\"<CUR>\",\n",
        "    lang=\"en\"  \n",
        ")\n",
        "\n",
        "\n",
        "df['content'] = df.content.apply(clean)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nclean(sample_txt,\\n    fix_unicode=True,               # fix various unicode errors\\n    to_ascii=True,                  # transliterate to closest ASCII representation\\n    lower=True,                     # lowercase text\\n    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\\n    no_urls=False,                  # replace all URLs with a special token\\n    no_emails=False,                # replace all email addresses with a special token\\n    no_phone_numbers=False,         # replace all phone numbers with a special token\\n    no_numbers=False,               # replace all numbers with a special token\\n    no_digits=False,                # replace all digits with a special token\\n    no_currency_symbols=False,      # replace all currency symbols with a special token\\n    no_punct = True,                 # fully remove punctuation\\n    replace_with_url=\"<URL>\",\\n    replace_with_email=\"<EMAIL>\",\\n    replace_with_phone_number=\"<PHONE>\",\\n    replace_with_number=\"<NUMBER>\",\\n    replace_with_digit=\"0\",\\n    replace_with_currency_symbol=\"<CUR>\",\\n    lang=\"en\"  \\n)\\n\\n\\ndf[\\'content\\'] = df.content.apply(clean)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwGMkhDzzWrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "0a03808d-210a-483d-d3c0-3f6fe3345d2d"
      },
      "source": [
        "df['content']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Update After getting a response from the devel...\n",
              "1        Used it for a fair amount of time without any ...\n",
              "2        Your app sucks now Used to be good but now doe...\n",
              "3        It seems OK but very basic Recurring tasks nee...\n",
              "4        Absolutely worthless This app runs a prohibiti...\n",
              "                               ...                        \n",
              "15741    I believe that this is by far the best app wit...\n",
              "15742                           It sometimes crashes a lot\n",
              "15743                           Works well for what I need\n",
              "15744                                              Love it\n",
              "15745    Really amazing and helped me sooo much just i ...\n",
              "Name: content, Length: 15746, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO2qBTVl_KPs"
      },
      "source": [
        "Some basic operations can convert the text to tokens and tokens to unique integers (ids):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTFhpHpsoWO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b1c07663-b38d-4391-e800-3d3d8afe09a5"
      },
      "source": [
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Sentence: When was I last outside? I am stuck at home for 2 weeks!!\n",
            "   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '!', '!']\n",
            "Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 106, 106]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzbbKLR8lZbu"
      },
      "source": [
        "### Special Tokens\n",
        "\n",
        "`[SEP]` - marker for ending of a sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXwz47bQvCbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd260d5b-e954-48d1-fa33-9cfcf547ab1d"
      },
      "source": [
        "tokenizer.sep_token, tokenizer.sep_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', 102)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mip_eGeXwLFF"
      },
      "source": [
        "`[CLS]` - we must add this token to the start of each sentence, so BERT knows we're doing classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6K4it5HwE6l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6533357e-61cd-40d8-9895-49ad2768a0cb"
      },
      "source": [
        "tokenizer.cls_token, tokenizer.cls_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS]', 101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi6O-yEY09gl"
      },
      "source": [
        "There is also a special token for padding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx7gD5xf1AFK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4ff7468-a3ed-4264-fcc4-7c8fda4a5417"
      },
      "source": [
        "tokenizer.pad_token, tokenizer.pad_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GWCfijM0TWB"
      },
      "source": [
        "BERT understands tokens that were in the training set. Everything else can be encoded using the `[UNK]` (unknown) token:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cmfFsbEKQDT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e5310b2-3e66-489d-f741-fbd075d58978"
      },
      "source": [
        "tokenizer.unk_token, tokenizer.unk_token_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[UNK]', 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L09HCNzhf9rS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9ap7jdL0LYU"
      },
      "source": [
        "All of that work can be done using the [`encode_plus()`](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer.encode_plus) method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vea9edaaxSPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2c7dfebc-8dae-4180-de28-bcc393444bb6"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS69c8WvdOED"
      },
      "source": [
        "The token ids are now stored in a Tensor and padded to a length of 32:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzBmcOla0yQR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d7a9e2ee-c772-4439-beb8-82361d970116"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 101, 1332, 1108,  146, 1314, 1796,  136,  146, 1821, 5342, 1120, 1313,\n",
              "        1111,  123, 2277,  106,  106,  102,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itAyVPsNdyc1"
      },
      "source": [
        "The attention mask has the same length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wiv5LLiw03Ox",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b4994552-0498-4784-b0f1-803f377194f4"
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RvhC4jNHHy"
      },
      "source": [
        "We can inverse the tokenization to have a look at the special tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IagGoafKLUwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "b7e3b08d-873e-46ed-c80b-767ebb142122"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'When',\n",
              " 'was',\n",
              " 'I',\n",
              " 'last',\n",
              " 'outside',\n",
              " '?',\n",
              " 'I',\n",
              " 'am',\n",
              " 'stuck',\n",
              " 'at',\n",
              " 'home',\n",
              " 'for',\n",
              " '2',\n",
              " 'weeks',\n",
              " '!',\n",
              " '!',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waKjYxTDuaWt"
      },
      "source": [
        "### Choosing Sequence Length\n",
        "\n",
        "BERT works with fixed-length sequences. We'll use a simple strategy to choose the max length. Let's store the token length of each review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUnE5CT9hbeZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7113d645-5a9b-4269-a00f-19e660db9cb6"
      },
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in df.content[1000]:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI4goUrHf6da"
      },
      "source": [
        "and plot the distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzE1j4jxmUtd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "177bed1e-e0ba-4d7d-8cf5-fa229440901f"
      },
      "source": [
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 718,
              "height": 489
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW6ajl30t6du"
      },
      "source": [
        "Most of the reviews seem to contain less than 128 tokens, but we'll be on the safe side and choose a maximum length of 160."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7xSmJtLuoxW"
      },
      "source": [
        "MAX_LEN = 160"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvvcoU6nurHy"
      },
      "source": [
        "We have all building blocks required to create a PyTorch dataset. Let's do it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2BPgRJ7YBK0"
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "      truncation=True\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2uwsvCYqDJK"
      },
      "source": [
        "The tokenizer is doing most of the heavy lifting for us. We also return the review texts, so it'll be easier to evaluate the predictions from our model. Let's split the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-vWzoo81dvO"
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xz3ZOQXVPCwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45b39f4f-d380-4b62-b05a-fead441eecdb"
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14171, 12), (787, 12), (788, 12))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwEdCwxK0bOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "cc16527a-d017-4bed-afb7-29f4a4409dee"
      },
      "source": [
        "df_train['content']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1562        You cant have your to do list as notifications\n",
              "15084    I havent been using this very long and its not...\n",
              "7417     1 Кривой и неработающий экспорт и импорт 2 Нел...\n",
              "12044    Love it so far Wish it had a widget for Androi...\n",
              "12410    Liked the prioritization by dragging and the h...\n",
              "                               ...                        \n",
              "5191     This app is not getting opened pls look after ...\n",
              "13418    Do not download this app There are Ads everyth...\n",
              "5390     The app keeps stopping repeatedly It would be ...\n",
              "860                   Very helpful and detailed applove it\n",
              "7270     Decent app but repeatedly asking me to pay a m...\n",
              "Name: content, Length: 14171, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4tQ1x-vqNab"
      },
      "source": [
        "We also need to create a couple of data loaders. Here's a helper function to do it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEGqcvkuOuTX"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "    reviews=df.content.to_numpy(),\n",
        "    targets=df.sentiment.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vODDxMKsPHqI"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6dlOptwqlhF"
      },
      "source": [
        "Let's have a look at an example batch from our training data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y93ldSN47FeT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "39c52138-aa81-4e07-e2d1-5042168038d0"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdU4YVqb7N8M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9e773962-c514-4aac-850f-8ef1c1ccc963"
      },
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 160])\n",
            "torch.Size([32, 160])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H63Y-TjyRC7S"
      },
      "source": [
        "## Sentiment Classification with BERT and Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "440Nd31VTHER"
      },
      "source": [
        "There are a lot of helpers that make using BERT easy with the Transformers library. Depending on the task you might want to use [BertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification), [BertForQuestionAnswering](https://huggingface.co/transformers/model_doc/bert.html#bertforquestionanswering) or something else. \n",
        "\n",
        "But who cares, right? We're *hardcore*! We'll use the basic [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel) and build our sentiment classifier on top of it. Let's load the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P41FayISNRI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "75196b79ff4640b39f02f4ee74dc49f4",
            "10a168364c6b47088b27841c63ff63e7",
            "4a07f30d670544dfb5c0e0d000d41f92",
            "4c00e7891513490dac8b69d08b8358e5",
            "310babb841f34b5c842a6abd15bfb5bc",
            "53f42edc57964019a24d81e782d94528",
            "d1beeca0e3284185848048965ed31da5",
            "9cd3680ac66c4ef584c2d343ad2a76d6",
            "eed7481eeb5c48268f5447a594c081ec",
            "300acc7f841b4ab1a39d1b6d7d37dce4",
            "9f30a5a842d649a6947e6e87dc3b944f",
            "15f2d5d6c7364ddb811c6f1a7387cebc",
            "104239cc072f49f999b5c2dfedca6958",
            "3c035c76981b4ac19db24d5e1c01c66b",
            "357bcf0ef4c2457ca16fc36876112cc9",
            "4b78f0212b5046d68c87fb284ff76e44"
          ]
        },
        "outputId": "b4c66476-3d8a-42f1-c49b-434a1e8cc729"
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75196b79ff4640b39f02f4ee74dc49f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eed7481eeb5c48268f5447a594c081ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFE7YSbFdY4t"
      },
      "source": [
        "And try to use it on the encoding of our sample text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1aoFxbQSn15"
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLu8zmqbaHV"
      },
      "source": [
        "The `last_hidden_state` is a sequence of hidden states of the last layer of the model. Obtaining the `pooled_output` is done by applying the [BertPooler](https://github.com/huggingface/transformers/blob/edf0582c0be87b60f94f41c659ea779876efc7be/src/transformers/modeling_bert.py#L426) on `last_hidden_state`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJHXNpIbcci",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "473cf890-5c88-4e57-84fe-0d330c2d39d1"
      },
      "source": [
        "last_hidden_state.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4dAot4zbz8k"
      },
      "source": [
        "We have the hidden state for each of our 32 tokens (the length of our example sequence). But why 768? This is the number of hidden units in the feedforward-networks. We can verify that by checking the config:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsxB7Qy7b5YN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0309046d-2007-4a2a-d32b-144387e1bfd7"
      },
      "source": [
        "bert_model.config.hidden_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTKi8-rTd_j4"
      },
      "source": [
        "\n",
        "\n",
        "You can think of the `pooled_output` as a summary of the content, according to BERT. Albeit, you might try and do better. Let's look at the shape of the output:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o_NiS3WgOFf"
      },
      "source": [
        "We can use all of this knowledge to create a classifier that uses the BERT model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mRflxPl32F"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJg8m3NQJahc"
      },
      "source": [
        "Our classifier delegates most of the heavy lifting to the BertModel. We use a dropout layer for some regularization and a fully-connected layer for our output. Note that we're returning the raw output of the last layer since that is required for the cross-entropy loss function in PyTorch to work.\n",
        "\n",
        "This should work like any other PyTorch model. Let's create an instance and move it to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0yQnuSFsjDp"
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCPCFDLlKIQd"
      },
      "source": [
        "We'll move the example batch of our training data to the GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7p__CqdaMO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "40c65b46-acf7-49c6-fb1c-a4e53c3280c8"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 160])\n",
            "torch.Size([32, 160])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr1EgkEtKOIB"
      },
      "source": [
        "To get the predicted probabilities from our trained model, we'll apply the softmax function to the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rTCj46Zamry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "f4edfe8a-5fe3-4604-bc81-58107c776965"
      },
      "source": [
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4101, 0.1600, 0.4299],\n",
              "        [0.5174, 0.1310, 0.3516],\n",
              "        [0.2787, 0.1325, 0.5887],\n",
              "        [0.5585, 0.1195, 0.3220],\n",
              "        [0.5926, 0.1753, 0.2321],\n",
              "        [0.3343, 0.1987, 0.4670],\n",
              "        [0.4099, 0.1327, 0.4574],\n",
              "        [0.3167, 0.2619, 0.4215],\n",
              "        [0.3325, 0.1465, 0.5211],\n",
              "        [0.2640, 0.2020, 0.5340],\n",
              "        [0.4048, 0.1508, 0.4443],\n",
              "        [0.3936, 0.2225, 0.3839],\n",
              "        [0.5717, 0.0732, 0.3552],\n",
              "        [0.4853, 0.1580, 0.3567],\n",
              "        [0.3946, 0.1789, 0.4265],\n",
              "        [0.3577, 0.2024, 0.4399],\n",
              "        [0.4874, 0.1277, 0.3850],\n",
              "        [0.4675, 0.0963, 0.4362],\n",
              "        [0.4166, 0.1260, 0.4574],\n",
              "        [0.3940, 0.2162, 0.3897],\n",
              "        [0.4574, 0.1629, 0.3797],\n",
              "        [0.3028, 0.1403, 0.5569],\n",
              "        [0.4741, 0.2120, 0.3139],\n",
              "        [0.3038, 0.2623, 0.4339],\n",
              "        [0.4993, 0.1498, 0.3510],\n",
              "        [0.4690, 0.1276, 0.4035],\n",
              "        [0.4261, 0.0988, 0.4750],\n",
              "        [0.4082, 0.1660, 0.4258],\n",
              "        [0.4054, 0.1610, 0.4336],\n",
              "        [0.5232, 0.1822, 0.2947],\n",
              "        [0.3560, 0.3131, 0.3309],\n",
              "        [0.5830, 0.1229, 0.2941]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L76jRVyqntCg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "756345de-c503-4e06-fc87-85c0b3f2aab4"
      },
      "source": [
        "type(input)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "method"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9xikRdtRN1N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76g7FV85H-T8"
      },
      "source": [
        "To reproduce the training procedure from the BERT paper, we'll use the [AdamW](https://huggingface.co/transformers/main_classes/optimizer_schedules.html#adamw) optimizer provided by Hugging Face. It corrects weight decay, so it's similar to the original paper. We'll also use a linear scheduler with no warmup steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBLTff3jdggN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "27d11924-8e26-4e97-b768-891281ff7a14"
      },
      "source": [
        "'''\n",
        "import numpy as np\n",
        "import torch  \n",
        "import math\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "import operator\n",
        "import functools\n",
        "from copy import copy\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "class AdaBound(Optimizer):\n",
        "    \"\"\"  AdaBound code from https://github.com/Luolc/AdaBound/blob/master/adabound/adabound.py\n",
        "    Implements AdaBound algorithm.\n",
        "    It has been proposed in `Adaptive Gradient Methods with Dynamic Bound of Learning Rate`_.\n",
        "    Arguments:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float, optional): Adam learning rate (default: 1e-3)\n",
        "        betas (Tuple[float, float], optional): coefficients used for computing\n",
        "            running averages of gradient and its square (default: (0.9, 0.999))\n",
        "        final_lr (float, optional): final (SGD) learning rate (default: 0.1)\n",
        "        gamma (float, optional): convergence speed of the bound functions (default: 1e-3)\n",
        "        eps (float, optional): term added to the denominator to improve\n",
        "            numerical stability (default: 1e-8)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        amsbound (boolean, optional): whether to use the AMSBound variant of this algorithm\n",
        "    .. Adaptive Gradient Methods with Dynamic Bound of Learning Rate:\n",
        "        https://openreview.net/forum?id=Bkg3g2R9FX\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), final_lr=0.1, gamma=1e-3,\n",
        "                 eps=1e-8, weight_decay=0, amsbound=False):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        if not 0.0 <= final_lr:\n",
        "            raise ValueError(\"Invalid final learning rate: {}\".format(final_lr))\n",
        "        if not 0.0 <= gamma < 1.0:\n",
        "            raise ValueError(\"Invalid gamma parameter: {}\".format(gamma))\n",
        "        defaults = dict(lr=lr, betas=betas, final_lr=final_lr, gamma=gamma, eps=eps,\n",
        "                        weight_decay=weight_decay, amsbound=amsbound)\n",
        "        super(AdaBound, self).__init__(params, defaults)\n",
        "\n",
        "        self.base_lrs = list(map(lambda group: group['lr'], self.param_groups))\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(AdaBound, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('amsbound', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group, base_lr in zip(self.param_groups, self.base_lrs):\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\n",
        "                        'Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "                amsbound = group['amsbound']\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "                    if amsbound:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                if amsbound:\n",
        "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    grad = grad.add(group['weight_decay'], p.data)\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                if amsbound:\n",
        "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
        "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
        "                    # Use the max. for normalizing running avg. of gradient\n",
        "                    denom = max_exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                else:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                bias_correction2 = 1 - beta2 ** state['step']\n",
        "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                # Applies bounds on actual learning rate\n",
        "                # lr_scheduler cannot affect final_lr, this is a workaround to apply lr decay\n",
        "                final_lr = group['final_lr'] * group['lr'] / base_lr\n",
        "                lower_bound = final_lr * (1 - 1 / (group['gamma'] * state['step'] + 1))\n",
        "                upper_bound = final_lr * (1 + 1 / (group['gamma'] * state['step']))\n",
        "                step_size = torch.full_like(denom, step_size)\n",
        "                step_size.div_(denom).clamp_(lower_bound, upper_bound).mul_(exp_avg)\n",
        "\n",
        "                p.data.add_(-step_size)\n",
        "\n",
        "        return loss\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport numpy as np\\nimport torch  \\nimport math\\nimport torch\\nfrom torch.optim import Optimizer\\nimport operator\\nimport functools\\nfrom copy import copy\\nfrom math import sqrt\\nimport matplotlib.pyplot as plt\\n\\nif torch.cuda.is_available():\\n    device = torch.device(\"cuda:0\")\\nelse:\\n    device = torch.device(\"cpu\")\\n\\n\\nclass AdaBound(Optimizer):\\n    \"\"\"  AdaBound code from https://github.com/Luolc/AdaBound/blob/master/adabound/adabound.py\\n    Implements AdaBound algorithm.\\n    It has been proposed in `Adaptive Gradient Methods with Dynamic Bound of Learning Rate`_.\\n    Arguments:\\n        params (iterable): iterable of parameters to optimize or dicts defining\\n            parameter groups\\n        lr (float, optional): Adam learning rate (default: 1e-3)\\n        betas (Tuple[float, float], optional): coefficients used for computing\\n            running averages of gradient and its square (default: (0.9, 0.999))\\n        final_lr (float, optional): final (SGD) learning rate (default: 0.1)\\n        gamma (float, optional): convergence speed of the bound functions (default: 1e-3)\\n        eps (float, optional): term added to the denominator to improve\\n            numerical stability (default: 1e-8)\\n        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\\n        amsbound (boolean, optional): whether to use the AMSBound variant of this algorithm\\n    .. Adaptive Gradient Methods with Dynamic Bound of Learning Rate:\\n        https://openreview.net/forum?id=Bkg3g2R9FX\\n    \"\"\"\\n\\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), final_lr=0.1, gamma=1e-3,\\n                 eps=1e-8, weight_decay=0, amsbound=False):\\n        if not 0.0 <= lr:\\n            raise ValueError(\"Invalid learning rate: {}\".format(lr))\\n        if not 0.0 <= eps:\\n            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\\n        if not 0.0 <= betas[0] < 1.0:\\n            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\\n        if not 0.0 <= betas[1] < 1.0:\\n            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\\n        if not 0.0 <= final_lr:\\n            raise ValueError(\"Invalid final learning rate: {}\".format(final_lr))\\n        if not 0.0 <= gamma < 1.0:\\n            raise ValueError(\"Invalid gamma parameter: {}\".format(gamma))\\n        defaults = dict(lr=lr, betas=betas, final_lr=final_lr, gamma=gamma, eps=eps,\\n                        weight_decay=weight_decay, amsbound=amsbound)\\n        super(AdaBound, self).__init__(params, defaults)\\n\\n        self.base_lrs = list(map(lambda group: group[\\'lr\\'], self.param_groups))\\n\\n    def __setstate__(self, state):\\n        super(AdaBound, self).__setstate__(state)\\n        for group in self.param_groups:\\n            group.setdefault(\\'amsbound\\', False)\\n\\n    def step(self, closure=None):\\n        \"\"\"Performs a single optimization step.\\n        Arguments:\\n            closure (callable, optional): A closure that reevaluates the model\\n                and returns the loss.\\n        \"\"\"\\n        loss = None\\n        if closure is not None:\\n            loss = closure()\\n\\n        for group, base_lr in zip(self.param_groups, self.base_lrs):\\n            for p in group[\\'params\\']:\\n                if p.grad is None:\\n                    continue\\n                grad = p.grad.data\\n                if grad.is_sparse:\\n                    raise RuntimeError(\\n                        \\'Adam does not support sparse gradients, please consider SparseAdam instead\\')\\n                amsbound = group[\\'amsbound\\']\\n\\n                state = self.state[p]\\n\\n                # State initialization\\n                if len(state) == 0:\\n                    state[\\'step\\'] = 0\\n                    # Exponential moving average of gradient values\\n                    state[\\'exp_avg\\'] = torch.zeros_like(p.data)\\n                    # Exponential moving average of squared gradient values\\n                    state[\\'exp_avg_sq\\'] = torch.zeros_like(p.data)\\n                    if amsbound:\\n                        # Maintains max of all exp. moving avg. of sq. grad. values\\n                        state[\\'max_exp_avg_sq\\'] = torch.zeros_like(p.data)\\n\\n                exp_avg, exp_avg_sq = state[\\'exp_avg\\'], state[\\'exp_avg_sq\\']\\n                if amsbound:\\n                    max_exp_avg_sq = state[\\'max_exp_avg_sq\\']\\n                beta1, beta2 = group[\\'betas\\']\\n\\n                state[\\'step\\'] += 1\\n\\n                if group[\\'weight_decay\\'] != 0:\\n                    grad = grad.add(group[\\'weight_decay\\'], p.data)\\n\\n                # Decay the first and second moment running average coefficient\\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\\n                if amsbound:\\n                    # Maintains the maximum of all 2nd moment running avg. till now\\n                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\\n                    # Use the max. for normalizing running avg. of gradient\\n                    denom = max_exp_avg_sq.sqrt().add_(group[\\'eps\\'])\\n                else:\\n                    denom = exp_avg_sq.sqrt().add_(group[\\'eps\\'])\\n\\n                bias_correction1 = 1 - beta1 ** state[\\'step\\']\\n                bias_correction2 = 1 - beta2 ** state[\\'step\\']\\n                step_size = group[\\'lr\\'] * math.sqrt(bias_correction2) / bias_correction1\\n\\n                # Applies bounds on actual learning rate\\n                # lr_scheduler cannot affect final_lr, this is a workaround to apply lr decay\\n                final_lr = group[\\'final_lr\\'] * group[\\'lr\\'] / base_lr\\n                lower_bound = final_lr * (1 - 1 / (group[\\'gamma\\'] * state[\\'step\\'] + 1))\\n                upper_bound = final_lr * (1 + 1 / (group[\\'gamma\\'] * state[\\'step\\']))\\n                step_size = torch.full_like(denom, step_size)\\n                step_size.div_(denom).clamp_(lower_bound, upper_bound).mul_(exp_avg)\\n\\n                p.data.add_(-step_size)\\n\\n        return loss\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-ArJ2fCCcU"
      },
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias = False)\n",
        "#relative_step=False,scale_parameter=False\n",
        "#correct_bias = False\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8522g7JIu5J"
      },
      "source": [
        "How do we come up with all hyperparameters? The BERT authors have some recommendations for fine-tuning:\n",
        "\n",
        "- Batch size: 16, 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
        "- Number of epochs: 2, 3, 4\n",
        "\n",
        "We're going to ignore the number of epochs recommendation but stick with the rest. Note that increasing the batch size reduces the training time significantly, but gives you lower accuracy.\n",
        "\n",
        "Let's continue with writing a helper function for training our model for one epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzl9UhuNx1_Q"
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4PniYIte0fr"
      },
      "source": [
        "Training the model should look familiar, except for two things. The scheduler gets called every time a batch is fed to the model. We're avoiding exploding gradients by clipping the gradients of the model using [clip_grad_norm_](https://pytorch.org/docs/stable/nn.html#clip-grad-norm).\n",
        "\n",
        "Let's write another one that helps us evaluate the model on a given data loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXeRorVGIKre"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_rdSDBHhhCh"
      },
      "source": [
        "Using those two, we can write our training loop. We'll also store the training history:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhHoFNsxufs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de8c3416-5116-4b01-fe39-83d3625aee86"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.7362204879589598 accuracy 0.6638204784418884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.5912128782272339 accuracy 0.7420584498094028\n",
            "\n",
            "Epoch 2/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.4763057597872904 accuracy 0.8083409780537718\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.5213918656110763 accuracy 0.8043202033036849\n",
            "\n",
            "Epoch 3/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.30355773367509076 accuracy 0.8904099922376685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.5094059577584267 accuracy 0.841168996188056\n",
            "\n",
            "Epoch 4/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.21386184514359347 accuracy 0.9247053842354104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.48741949707269666 accuracy 0.8614993646759848\n",
            "\n",
            "Epoch 5/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.160806760393739 accuracy 0.9455931126949404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.557513479590416 accuracy 0.8589580686149937\n",
            "\n",
            "Epoch 6/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.12836669441459714 accuracy 0.957024910027521\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.5801958030462265 accuracy 0.8678526048284626\n",
            "\n",
            "Epoch 7/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.1054386734483137 accuracy 0.9650695081504481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.5709340944886208 accuracy 0.8792884371029225\n",
            "\n",
            "Epoch 8/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.08922229888854216 accuracy 0.9712793733681463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6215419083461166 accuracy 0.8678526048284626\n",
            "\n",
            "Epoch 9/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.07319936449860241 accuracy 0.9745254392773975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6702467332780361 accuracy 0.8703939008894537\n",
            "\n",
            "Epoch 10/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.06536385225030672 accuracy 0.9777715051866488\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6528360327333211 accuracy 0.8767471410419314\n",
            "\n",
            "Epoch 11/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.05961156281468913 accuracy 0.9805941711946934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.6889564372040331 accuracy 0.8754764930114358\n",
            "\n",
            "Epoch 12/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.0510421209930128 accuracy 0.9833462705525369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.7085402872413397 accuracy 0.8767471410419314\n",
            "\n",
            "Epoch 13/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.04610007063803131 accuracy 0.9846870369063581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.696982207968831 accuracy 0.8831003811944091\n",
            "\n",
            "Epoch 14/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.048039261051311746 accuracy 0.9838402371039447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.7155418902635574 accuracy 0.8805590851334181\n",
            "\n",
            "Epoch 15/15\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.04151261168639554 accuracy 0.9850398701573637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.7145133079588413 accuracy 0.8831003811944091\n",
            "\n",
            "CPU times: user 37min 42s, sys: 19min 49s, total: 57min 31s\n",
            "Wall time: 57min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8-5zWsiVur"
      },
      "source": [
        "Note that we're storing the state of the best model, indicated by the highest validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLQf52c7fbzr"
      },
      "source": [
        "Whoo, this took some time! We can look at the training vs validation accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FWG7kBm372V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "9e00fa11-7a4a-4598-d4b5-d713ecf5e500"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 732,
              "height": 506
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsHqkLAuf8pv"
      },
      "source": [
        "The training accuracy starts to approach 100% after 10 epochs or so. You might try to fine-tune the parameters a bit more, but this will be good enough for us.\n",
        "\n",
        "Don't want to wait? Uncomment the next cell to download my pre-trained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoGUH8VZ-pPQ"
      },
      "source": [
        "# !gdown --id 1V8itWtowCYnb2Bc9KlK9SxGff9WwmogA\n",
        "\n",
        "# model = SentimentClassifier(len(class_names))\n",
        "# model.load_state_dict(torch.load('best_model_state.bin'))\n",
        "# model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3HZb3NWFtFf"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "So how good is our model on predicting sentiment? Let's start by calculating the accuracy on the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS3gJ_qBEljD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "3c057c01-18e3-416d-fb24-e271de8b1124"
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8870558375634517"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdQ7-ylCj8Gd"
      },
      "source": [
        "The accuracy is about 1% lower on the test set. Our model seems to generalize well.\n",
        "\n",
        "We'll define a helper function to get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgR6MuNS8jr_"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkbnBTI7kd_y"
      },
      "source": [
        "This is similar to the evaluation function, except that we're storing the text of the reviews and the predicted probabilities (by applying the softmax on the model outputs):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdPZr60-0c_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "0cb7a704-24e3-4dfd-d8dc-9a260732f7a5"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVwoVij2lC7F"
      },
      "source": [
        "Let's have a look at the classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8a9_8-ND3Is",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "c3982f47-0616-48ed-c09d-3bf95e7e1fee"
      },
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.91      0.87      0.89       245\n",
            "     neutral       0.83      0.86      0.84       254\n",
            "    positive       0.92      0.92      0.92       289\n",
            "\n",
            "    accuracy                           0.89       788\n",
            "   macro avg       0.89      0.89      0.89       788\n",
            "weighted avg       0.89      0.89      0.89       788\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFAekw3mmWUi"
      },
      "source": [
        "Looks like it is really hard to classify neutral (3 stars) reviews. And I can tell you from experience, looking at many reviews, those are hard to classify.\n",
        "\n",
        "We'll continue with the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d1qxsc__DTh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "d0e5fb06-b95e-4036-877d-ebe18d8436d7"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 725,
              "height": 516
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx0U7oNsnZ3A"
      },
      "source": [
        "This confirms that our model is having difficulty classifying neutral reviews. It mistakes those for negative and positive at a roughly equal frequency.\n",
        "\n",
        "That's a good overview of the performance of our model. But let's have a look at an example from our test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iANBiY3sLo-K"
      },
      "source": [
        "idx = 2\n",
        "\n",
        "review_text = y_review_texts[idx]\n",
        "true_sentiment = y_test[idx]\n",
        "pred_df = pd.DataFrame({\n",
        "  'class_names': class_names,\n",
        "  'values': y_pred_probs[idx]\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8D0rb1yfnv4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b5272f05-e466-495a-fafd-8a2e95e600ac"
      },
      "source": [
        "print(\"\\n\".join(wrap(review_text)))\n",
        "print()\n",
        "print(f'True sentiment: {class_names[true_sentiment]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I used to use Habitica and I must say this is a great step up Id like\n",
            "to see more social features such as sharing tasks only one person has\n",
            "to perform said task for it to be checked off but only giving that\n",
            "person the experience and gold Otherwise the price for subscription is\n",
            "too steep thus resulting in a subperfect score I could easily justify\n",
            "099month or eternal subscription for 15 If that price could be met as\n",
            "well as fine tuning this would be easily worth 5 stars\n",
            "\n",
            "True sentiment: neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7hj_IZFnn2X"
      },
      "source": [
        "Now we can look at the confidence of each sentiment of our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj4d8lZyMkhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "66a33d1e-820d-49f4-9c0d-6967b16b7831"
      },
      "source": [
        "sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n",
        "plt.ylabel('sentiment')\n",
        "plt.xlabel('probability')\n",
        "plt.xlim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 779,
              "height": 489
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WL5pDmvFyaU"
      },
      "source": [
        "### Predicting on Raw Text\n",
        "\n",
        "Let's use our model to predict the sentiment of some raw text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEPi7zQRsDhH"
      },
      "source": [
        "review_text = \"I love completing my todos! Best app ever!!!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaN4RnqMnxYw"
      },
      "source": [
        "We have to use the tokenizer to encode the text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA5Or4D2sLc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "aab9f855-cd34-42bf-8b9e-fded4fff192b"
      },
      "source": [
        "encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et8xlDrKpH60"
      },
      "source": [
        "Let's get the predictions from our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr_t3rUksumr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "291251b3-b333-40ac-cb80-346d70698993"
      },
      "source": [
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "output = model(input_ids, attention_mask)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "\n",
        "print(f'Review text: {review_text}')\n",
        "print(f'Sentiment  : {class_names[prediction]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review text: I love completing my todos! Best app ever!!!\n",
            "Sentiment  : positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVhwzq7bpPRl"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Nice job! You learned how to use BERT for sentiment analysis. You built a custom classifier using the Hugging Face library and trained it on our app reviews dataset!\n",
        "\n",
        "- [Read the tutorial](https://www.curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/)\n",
        "- [Run the notebook in your browser (Google Colab)](https://colab.research.google.com/drive/1PHv-IRLPCtv7oTcIGbsgZHqrB5LPvB7S)\n",
        "- [Read the `Getting Things Done with Pytorch` book](https://github.com/curiousily/Getting-Things-Done-with-Pytorch)\n",
        "\n",
        "You learned how to:\n",
        "\n",
        "- Intuitively understand what BERT is\n",
        "- Preprocess text data for BERT and build PyTorch Dataset (tokenization, attention masks, and padding)\n",
        "- Use Transfer Learning to build Sentiment Classifier using the Transformers library by Hugging Face\n",
        "- Evaluate the model on test data\n",
        "- Predict sentiment on raw text\n",
        "\n",
        "Next, we'll learn how to deploy our trained model behind a REST API and build a simple web app to access it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf39tauBa2V2"
      },
      "source": [
        "## References\n",
        "\n",
        "- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
        "- [L11 Language Models - Alec Radford (OpenAI)](https://www.youtube.com/watch?v=BnpB3GrpsfM)\n",
        "- [The Illustrated BERT, ELMo, and co.](https://jalammar.github.io/illustrated-bert/)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "- [How to Fine-Tune BERT for Text Classification?](https://arxiv.org/pdf/1905.05583.pdf)\n",
        "- [Huggingface Transformers](https://huggingface.co/transformers/)\n",
        "- [BERT Explained: State of the art language model for NLP](https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270)"
      ]
    }
  ]
}